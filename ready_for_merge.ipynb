{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Centroid #\n",
    "# Holds the centroid of the first image as a refrence\n",
    "base_centroid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Functions #\n",
    "def plot_all_needed_images(dict_img):\n",
    "    # Function to take a dictionary of images and plot them and their histograms #\n",
    "\n",
    "    # iterating through the dictionary and plotting each needed image along with it's histogram\n",
    "    for key in dict_img:\n",
    "        img = dict_img[key]\n",
    "        # Plot the image\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f'{key}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot the histogram\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(img.ravel(), bins=256, range=[0, 256], color='gray')\n",
    "        plt.xlabel('Pixel Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Grayscale Histogram')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "def find_centroid(contour):\n",
    "    # Finds the centroid of a contour #\n",
    "    M = cv2.moments(contour)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    return cx,cy\n",
    "def get_hough(img):\n",
    "    # Find the Hough transfrom of the image #\n",
    "    \n",
    "    # Apply Canny edge detection \n",
    "    edges = cv2.Canny(img, 50, 150)\n",
    "    # Apply Hough transfrom\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=30, minLineLength=50, maxLineGap=190)\n",
    "    # Draw Hough lines on a black mask and return it\n",
    "    mask = np.zeros_like(img)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(mask, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "    return mask\n",
    "def get_contour(houghImg):\n",
    "    # Find the exact and approximate contour of the qr code #\n",
    "\n",
    "    # Find contours in the hough image\n",
    "    contours, _ = cv2.findContours(houghImg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Filter contours that have 4 edge points and max area\n",
    "    max_area = 0\n",
    "    selected_contour_exact = None\n",
    "    selected_contour_appx = None\n",
    "\n",
    "    for contour in contours:\n",
    "        epsilon = 0.1 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        if len(approx) == 4:  \n",
    "            # Calculate the area of the contour\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                selected_contour_exact = contour\n",
    "                selected_contour_appx = approx\n",
    "    return (selected_contour_exact, selected_contour_appx)\n",
    "def find_point_with_yMax (cont):\n",
    "    # Finding the bottom right point #\n",
    "    max_y = 0\n",
    "    max_point = None\n",
    "    for point in cont:\n",
    "        if point[0] > max_y:\n",
    "            max_y = point[0]\n",
    "            max_point = point\n",
    "    return max_point\n",
    "def find_point_with_xMminYMax (cont):\n",
    "    # Finding the top right point #\n",
    "    min_x = 9999\n",
    "    min_points = []\n",
    "    for point in cont:\n",
    "        if point[1] <= min_x:\n",
    "            min_x = point[1]\n",
    "            min_points.append(point) \n",
    "    return find_point_with_yMax(min_points)\n",
    "def find_angle(vec):\n",
    "    #Find angle between the vector and the y-axis#\n",
    "    y_axis = np.array([0, 1])\n",
    "\n",
    "    # Calculate the dot product\n",
    "    dot_product = np.dot(vec, y_axis)\n",
    "\n",
    "    # Calculate the magnitudes of the vectors\n",
    "    magnitude1 = np.linalg.norm(vec)\n",
    "    magnitude2 = np.linalg.norm(y_axis)\n",
    "\n",
    "    # Calculate the cosine of the angle between the 2 lines\n",
    "    cosine_angle = dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "    # Calculate the angle in degrees\n",
    "    return (np.arccos(cosine_angle) * 180 / np.pi)\n",
    "def rotate_img_clockwise(img, angle):\n",
    "    h,w = img.shape[:2]\n",
    "    # Calculate the rotation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((w / 2, h / 2), -angle, 1)\n",
    "    # Perform the rotation\n",
    "    return (cv2.warpAffine(img, rotation_matrix, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255)))\n",
    "def translate_to_middle(img, contour, tolerance_x=0, tolerance_y=0):\n",
    "    # Translate the image to the middle of the frame #\n",
    "\n",
    "    # Centroid of base image is right at the middle, Whiler Centroid of the #\n",
    "    # current image is not, thus tolerance is added to correct this difference # \n",
    "\n",
    "    h,w = img.shape[:2]\n",
    "    # Find img centroid\n",
    "    old_centroid = find_centroid(contour=contour)\n",
    "    # Find the translation matrix to the base centroid\n",
    "    tx = base_centroid[0] - old_centroid[0] + tolerance_x\n",
    "    ty = base_centroid[1] - old_centroid[1] + tolerance_y\n",
    "    translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "    # Translate the image\n",
    "    return (cv2.warpAffine(img, translation_matrix, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255)))\n",
    "\n",
    "def shift_perspective(img, contour, target_verticies):\n",
    "\n",
    "    h,w = img.shape[:2]\n",
    "    \n",
    "    #   Original verticies from the contour\n",
    "    bottom_left, top_left, top_right, bottom_right = contour.reshape(-1, 2)\n",
    "    original_verticies = np.array([bottom_left, top_left, top_right, bottom_right], dtype= np.float32)\n",
    "\n",
    "    # Apply prespective transfrom\n",
    "    perspective_transform_matrix = cv2.getPerspectiveTransform(original_verticies, target_verticies)\n",
    "    return (cv2.warpPerspective(img, perspective_transform_matrix, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testcase 1 #\n",
    "def tc01_preprocessing(original_img):\n",
    "    \n",
    "    # Find hough\n",
    "    hough_lines_1 = get_hough(original_img)\n",
    "    # Find contours\n",
    "    exact,appx = get_contour(hough_lines_1)\n",
    "    # Find base centroid\n",
    "    global base_centroid\n",
    "    base_centroid = find_centroid(exact)\n",
    "    # Draw contour\n",
    "    cont_img = original_img.copy()\n",
    "    if exact is not None:\n",
    "        cv2.drawContours(cont_img, [exact], -1, (0, 0, 0), 4)\n",
    "    # Construnct the printing dictionary\n",
    "    printing_dict = {\n",
    "        'QR itself': original_img,\n",
    "        'Detected Outline' : cont_img,\n",
    "    }\n",
    "    return printing_dict\n",
    "\n",
    "img_1 = cv2.imread('./images/01-Getting-started.png', cv2.IMREAD_GRAYSCALE)\n",
    "dict_1 = tc01_preprocessing(img_1)\n",
    "plot_all_needed_images(dict_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testcase 2 #\n",
    "def tc02_preprocessing(original_img):\n",
    "    \n",
    "    # Pad the image so we can draw complete lines in the hough transform\n",
    "    padding = 10\n",
    "    padded_img = cv2.copyMakeBorder(original_img, padding, padding, padding, padding, cv2.BORDER_CONSTANT, value=(255,255,255))\n",
    "    # Find Hough\n",
    "    hough_lines_2 = get_hough(padded_img)\n",
    "    # Find Contour\n",
    "    exact,appx = get_contour(hough_lines_2)\n",
    "    # Draw contour\n",
    "    cont_img = original_img.copy()\n",
    "    if exact is not None:\n",
    "        cv2.drawContours(cont_img, [exact], -1, (0, 0, 0), 4)\n",
    "    # Find angle between contour side and y-axis \n",
    "    p1 = find_point_with_xMminYMax(exact.reshape(-1, 2))\n",
    "    p2 = find_point_with_yMax(exact.reshape(-1, 2))\n",
    "    vector = p2-p1\n",
    "    angle = find_angle(vector) # 8.38 degrees\n",
    "    # Rotate the image\n",
    "    rotated_img = rotate_img_clockwise(padded_img, angle)\n",
    "    # Translate the image\n",
    "    translated_img = translate_to_middle(rotated_img, exact, tolerance_y= 30)\n",
    "    # Construct the printing dictionary\n",
    "    printing_dict = {\n",
    "        'QR itself': original_img,\n",
    "        'Detected Outline' : cont_img,\n",
    "        'Rotated Image' : rotated_img,\n",
    "        'Translated Image' : translated_img\n",
    "    }\n",
    "    return printing_dict\n",
    "\n",
    "img_2 = cv2.imread('./images/02-Matsawar-3edel-ya3am.png', cv2.IMREAD_GRAYSCALE)\n",
    "dict_2 = tc02_preprocessing(img_2)\n",
    "plot_all_needed_images(dict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testcase 3 #\n",
    "def tc03_preprocessing(original_img):\n",
    "    \n",
    "    # Reading the original image\n",
    "    img = cv2.imread('images/03-Leffy-bina-ya-donya.png')\n",
    "    # Find Hough\n",
    "    hough_lines_3 = get_hough(original_img)\n",
    "    # Find Contour\n",
    "    exact,appx = get_contour(hough_lines_3)\n",
    "    # Draw contour\n",
    "    cont_img = original_img.copy()\n",
    "    if exact is not None:\n",
    "        cv2.drawContours(cont_img, [exact], -1, (0, 0, 0), 4) \n",
    "    # Rotate image\n",
    "    rotated_img = rotate_img_clockwise(original_img, 180)\n",
    "    # Construct the printing dictionary\n",
    "    printing_dict = {\n",
    "        'QR itself': original_img,\n",
    "        'Detected Outline' : cont_img,\n",
    "        'Rotated Image' : rotated_img\n",
    "    }\n",
    "    return printing_dict\n",
    "    \n",
    "img_3 = cv2.imread('./images/03-Leffy-bina-ya-donya.png', cv2.IMREAD_GRAYSCALE)\n",
    "dict_3 = tc03_preprocessing(img_3)\n",
    "plot_all_needed_images(dict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testcase 14 #\n",
    "def tc14_preprocessing(original_img):\n",
    "\n",
    "    # Threshold the image to remove banana\n",
    "    _, thresh_img = cv2.threshold(original_img, 90, 255, cv2.THRESH_BINARY)\n",
    "    # Find Hough\n",
    "    hough_lines_14 = get_hough(thresh_img)\n",
    "    # Find the approximate Contour\n",
    "    exact,appx = get_contour(hough_lines_14)\n",
    "    # Draw approximate Contour\n",
    "    cont_img = original_img.copy()\n",
    "    if appx is not None:\n",
    "        cv2.drawContours(cont_img, [appx], -1, (0, 0, 0), 4) \n",
    "    # Fitting the QR code into a square\n",
    "\n",
    "    # Target verticies (Base image verticies)\n",
    "    target_verticies = np.array([[967,42], [42,42], [42,967], [967,967]], dtype= np.float32)\n",
    "\n",
    "    warped_image = shift_perspective(original_img, appx, target_verticies)\n",
    "\n",
    "    # Apply thresholding\n",
    "    _, thresh_shifted_img = cv2.threshold(warped_image, 60, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    \n",
    "    # Construct the printing dictionary\n",
    "    printing_dict = {\n",
    "        'QR itself': original_img,\n",
    "        'Detected Outline' : cont_img,\n",
    "        'After Prespective shift' : thresh_shifted_img\n",
    "    }\n",
    "    return printing_dict\n",
    "    \n",
    "img_14 = cv2.imread('./images/14-BANANAAA!!!.png', cv2.IMREAD_GRAYSCALE)\n",
    "dict_14 = tc14_preprocessing(img_14)\n",
    "plot_all_needed_images(dict_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testcase 6 #\n",
    "def tc06_preprocessing(original_img):\n",
    "\n",
    "    # Find Hough\n",
    "    hough_lines_6 = get_hough(original_img)\n",
    "    # Find the approximate Contour\n",
    "    exact,appx = get_contour(hough_lines_6)\n",
    "    # Draw approximate Contour\n",
    "    cont_img = original_img.copy()\n",
    "    if appx is not None:\n",
    "        cv2.drawContours(cont_img, [appx], -1, (0, 0, 0), 4) \n",
    "    # Fitting the QR code into a square #\n",
    "    # Find contour edge vertices\n",
    "    bottom_left, top_left, top_right, bottom_right = appx.reshape(-1, 2)\n",
    "    # Calculate new edge vertices positions\n",
    "    top_left = [top_right[0], bottom_left[1]]\n",
    "    bottom_right = [bottom_left[0], top_right[1]]\n",
    "    target_verticies = np.array([bottom_left, top_left, top_right, bottom_right], dtype= np.float32)\n",
    "    warped_image = shift_perspective(original_img, appx, target_verticies)\n",
    "    \n",
    "    # Construct the printing dictionary\n",
    "    printing_dict = {\n",
    "        'QR itself': original_img,\n",
    "        'Detected Outline' : cont_img,\n",
    "        'After Prespective shift' : warped_image\n",
    "    }\n",
    "    return printing_dict\n",
    "    \n",
    "img_6 = cv2.imread('./images/06-Railfence-cipher.png', cv2.IMREAD_GRAYSCALE)\n",
    "dict_6 = tc06_preprocessing(img_6)\n",
    "plot_all_needed_images(dict_6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rasa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
